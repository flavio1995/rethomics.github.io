[
["index.html", "Rethomics, a framework for high-throughput behaviour analysis in R Introduction", " Rethomics, a framework for high-throughput behaviour analysis in R Quentin Geissmann 2017-11-27 Introduction Only if we share a common data structure can we use a common set of tools The rethomics framework unify behaviour analysis over multiple platforms In the last few years, there has been growing interests in ethomics – that is, the analysis of large behavioural data sets. Many software and hardware solutions have been proposed to record different behavioural variables on several model organisms. Although subsequent analysis and visualisation share many similarities, each method tends to provide its own output format and, in practice, its own restricted analysis software. This results in a lot of replicated work but also limits extension and collaboration. Rethomics attempts to unify analysis of behaviour by providing several packages: behavr tables – a flexible and universal structure to handle very large behavioural data sets damr, scopr, … – to load data from DAMS, ethoscopes and others into behavr tables ggetho – based on ggplot2, to produce high-quality representations of behavioural data sleepr, zeitgebr, … – to analyse behavioural data (sleep analysis, circadian rhythm, …) This document is a tutorial intended for experimenters as well as data analysts. It provides a suite of both conceptual explanations and very concrete examples. "],
["intro.html", "First Steps Getting R Installing rethomics packages List of rethomics packages", " First Steps Getting R If you have never used or heard of R before, I suggest you start by reading about data science in R and installing RStudio. Only once you have done can we continue. Installing rethomics packages As of today (2017-11-27), rethomics packages are not on CRAN, the official R package archive yet. Therefore, we will install the developmental version. As a prerequisite, we need to install (once for all) devtools and load it: install.packages(&quot;devtools&quot;) library(devtools) Ensure you have no error messages. Then, we can install some of the rethomics packages. For instance, lets install behavr. install_github(&quot;rethomics/behavr&quot;) In the same way, you could replace behavr by another package. For instance, you could install ggetho with install_github(&quot;rethomics/ggetho&quot;). List of rethomics packages Below is a list of all the rethomics packages as well as their individual PDF documentation, description and build status. Package Doc Description Travis.CI Coverage behavr Canonical Data Structure for Behavioural Data ggetho Visualise High-Throughput Behavioural (i.e. Ethomics) Data damr Read Drosophila Activity Monitor Data scopr Read Ethoscope Data sleepr Analyse Activity and Sleep Behaviour zeitgebr Analyse and Visualise Circadian Behaviours "],
["workflow.html", "The rethomics workflow", " The rethomics workflow From hypothesis to results The rethomics workflow In rethomics, we envisage behavioural experiments as a workflow: Design – you plan your experiment (I can’t really help you with that, but I trust you!). Record/track – you use your acquisition platfrom to record behavioural variables over time. They define the format of the results. Write individual information – you make a spreadsheet (CSV file) that details the experimental conditions for each individual. We call this a metadata file. It is a crucial concept in rethomics, so we will dedicate it the next section. You can often write your metadata as you plan your experiment, but sometimes, you want to enrich it with variables that you can only record after your experiment (e.g. lifespan). Link and Load data – First, we enrich your metadata by “linking” it to the result. This allows you to load all the matching data into a singlebehavr table (see section on behavr tables). Tranform &amp; analyse &amp; visualise – you take advantage of rethomics and R analysis and visualisation tools. "],
["metadata.html", "Working with metadata files What are metadata? Make them exhaustive Put replicates together Linking metadata Take home message", " Working with metadata files Using and understanding metadata files makes your analyses more transparent and tracktable Schematic of a metadata file What are metadata? When performing many experiments, with multiple condidions and replicates, it becomes challenging to keep track of each individual and to link it to its actual data. In rethomics, regardless of the tool used to generate data, loading results always involves a metadata file. It is, in fact, a simple CSV file (basically a spreadsheet) in which each row defines one unique individual. As shown in the figure above, metadata is classified in two types of columns: Mandatory techincal columns – for instance date, machine_name and others (depending on the acquisition platform). They will be used to match an animal to its data. Optional experimental columns – in this example, condition and sex. You can use as all the columns you want to characterise your experiments. Make them exhaustive It is a good habit to record as much information as possible in our metadata – even if it seems redundant. For instance, if we put animals in different incubators, we can simply add an incubator column. This way, we keep all our experimental notes, as much as possible, inside one file. Not only this will help us to “debug” if anything goes wrong in one incubator, but we will also be able to account for incubator as a covariate later on. From a computational perspective, these columns are virtually free. Put replicates together A common mistake for users is to perform several replicates of the same experiment and to make a new metadata file each time. Instead, I strongly recommand you to put all replicates in the same file. If it helps, you can add a replicate column so you can keep track of which replicate each animal comes from. The whole point of high-througput analysis is that you can load all the data from all replicates and compare it (and maybe merge it). The bottom line is that, if you start form a single metadata file, your work will be more tracktable, and you can always decide to analyse only one replicate at a time. Linking metadata Linking adds technical columns Once your metadata is ready, it can be used to create a query to import the matching data. Regardless of which acquisition tool you used, the first step when importing data in R will be “metadata linking”. This step will automatically complete the metadata file in a way that can be used for R to retrieve the right amount of data from experiment files. We call it linking, since it links the manually introduced metadata with the right experiment data file, something that is tedious to do manually. In short, linking means at least: Adding an id column to the metadata. This will be a unique identifier for each indididual (it generally contains datetime, machine name an region id). This will diferenciate animals with the same conditions in the metadata. Adding a column that tracks “how to find the data for each individual”. Take home message In conclusion, metadatafiles are a canonical way to both define experimental condition and load behavioural data. They are both computer and human friendly. In other words, if you give a query to a colaborator, she/he will be able to tell very quickly what animal underwent which treatment, where and when. "],
["behavr.html", "behavr tables Variables and metavariables Operating on behavr tables Playing with toy data Generalities", " behavr tables A single data structure to store data and metadata a behavr table Variables and metavariables As we have seen in the previous section, metadata are crucial for proper statistical analysis of behavioural data. The point of an experiment, is however to acquire data. That is, a long time series of recorded variables such as position, orientation and number of beam crosses, for each individual. Variables are different form metavariables in so far as the latter are made of only one value per animal. It is easier (and less error prone) to always keep the data and metadata together. In rethomics, in order to handle large amounts of data (together with metadata), we have designed the behavr package. behavr tables are based on the very powerful package data.table, but enhanced with metadata. For most purposes, you can use a behavr table just like a data.table. Therefore, have a look at the introduction to data.table further detail! When we load any behavioural data in rethomics, we get a behavr table as a result. In this section, we will discuss the usual operations that you can perform on behavr tables. Operating on behavr tables Now that we have all our data at the same place, we want to be able to manipulate it. In the next part of this tutorial, we will create some toy data and learn how to manipulate it. This table is a short overview: Section Operation Expression Example Generalities Summarise behavr table summary(DT) How many individuals, variables, metavariables, etc? – summary(dt) Pure data Create/alter a variable DT[, new_column := some_value] When are aninimals ‘very active’? – dt[, very_active := activity &gt;= 2] Remove a variable DT[, column_to_delete := NULL] Lets remove a variable we don’t need? – dt[, very_active := NULL] Select data rows DT[criteria] Exclude data before the first hour – small_dt &lt;- dt[t &gt; hours(1)] Pure metadata Access metadata table DT[meta = TRUE] Show metadata as table – dt[meta = TRUE] Create/alter metavariable DT[, new_meta := some_value, meta=TRUE] Define a new factor that is a comibiation of ‘sex x condition’ – dt[, treatment := paste(sex, condition, sep='|'), meta=T] Meta &amp; data Use metavariable as variable xmv(metavariable) Add 10s to all time, only for animals in condition 'A' – dt[, t := ifelse(xmv(condition) == 'A', t + 10, t)] Remove individuals according to metavariable DT[criteria] Remove all males (from data, and metadata) – dt_males &lt;- dt[xmv(sex) == 'females'] Summarise Compute indidisual statistics DT[, .( statistics = some_math()), by='id'] Compute the average activity, per animal – stat_dt &lt;- dt[, .(mean_acti = mean(active)), by='id'] Rejoin metadata to data rejoin(DT) Merge metadata and summary statistics – stat_dt &lt;- rejoin(stat_dt) Advanced Stitch experiments stitch_on(DT, metavariable) TODO – TODO Playing with toy data The behavr package has a set of functions to make toy data. In order to have a look at a behavr object, lets create one. First, we make the metadata: library(behavr) ## Loading required package: data.table metadata &lt;- data.table( id = paste(&quot;toy_experiment&quot;, 1:10, sep = &quot;|&quot;), sex = rep(c(&quot;male&quot;, &quot;female&quot;), each = 5), condition = c(&quot;A&quot;, &quot;B&quot;) ) metadata ## id sex condition ## 1: toy_experiment|1 male A ## 2: toy_experiment|2 male B ## 3: toy_experiment|3 male A ## 4: toy_experiment|4 male B ## 5: toy_experiment|5 male A ## 6: toy_experiment|6 female B ## 7: toy_experiment|7 female A ## 8: toy_experiment|8 female B ## 9: toy_experiment|9 female A ## 10: toy_experiment|10 female B Then, we use toy_dam_data() to simulate (instead of linking/loading) one day of DAMS-like data for these ten animals (and two conditions): dt &lt;- toy_dam_data(metadata, duration = days(1)) dt ## ## ==== METADATA ==== ## ## id sex condition ## &lt;char&gt; &lt;char&gt; &lt;char&gt; ## 1: toy_experiment|1 male A ## 2: toy_experiment|10 female B ## 3: toy_experiment|2 male B ## 4: toy_experiment|3 male A ## 5: toy_experiment|4 male B ## 6: toy_experiment|5 male A ## 7: toy_experiment|6 female B ## 8: toy_experiment|7 female A ## 9: toy_experiment|8 female B ## 10: toy_experiment|9 female A ## ## ====== DATA ====== ## ## id t activity ## &lt;char&gt; &lt;num&gt; &lt;int&gt; ## 1: toy_experiment|1 0 0 ## 2: toy_experiment|1 60 2 ## 3: toy_experiment|1 120 0 ## 4: toy_experiment|1 180 1 ## --- ## 14406: toy_experiment|9 86160 0 ## 14407: toy_experiment|9 86220 0 ## 14408: toy_experiment|9 86280 2 ## 14409: toy_experiment|9 86340 1 ## 14410: toy_experiment|9 86400 0 As you can see, when we print dt, our behavr table, we have two fields: METADATA and DATA. The former is actually just the metadata we created whilst the latter stores the data (i.e. the variables) for all animals. The special column id is also known as a key, and is shared between both data and metadata. It inernally allows us to map them to one another. In other words, it is a unique id for each individual. In this specific example, the variables t and activity are the time and the number of beam crosses, respectively. Generalities A quick way to retreive general information about a behavr table is to use summary: summary(dt) ## behavr table with: ## 10 individuals ## 2 metavariables ## 2 variables ## 1.441e+04 measurements ## 1 key (id) This tells us immediately how many variables, metavariables and data points, we have. One can also print a detailed summary (i.e. one per animal): summary(dt, detailed = TRUE) ## ## Summary of each individual (one per row): ## id sex condition data_points time_range ## 1: toy_experiment|1 male A 1441 [0 -&gt; 86400 (86400)] ## 2: toy_experiment|10 female B 1441 [0 -&gt; 86400 (86400)] ## 3: toy_experiment|2 male B 1441 [0 -&gt; 86400 (86400)] ## 4: toy_experiment|3 male A 1441 [0 -&gt; 86400 (86400)] ## 5: toy_experiment|4 male B 1441 [0 -&gt; 86400 (86400)] ## 6: toy_experiment|5 male A 1441 [0 -&gt; 86400 (86400)] ## 7: toy_experiment|6 female B 1441 [0 -&gt; 86400 (86400)] ## 8: toy_experiment|7 female A 1441 [0 -&gt; 86400 (86400)] ## 9: toy_experiment|8 female B 1441 [0 -&gt; 86400 (86400)] ## 10: toy_experiment|9 female A 1441 [0 -&gt; 86400 (86400)] Data Playing with variables is just like in data.table. Read the official data.table tutorial for more functionalities. For instance, we can add a new variable, very_active, that is TRUE if and only if there was at least two beam crosses in a minute, for a given individual: dt[, very_active := activity &gt;= 2] If we decide we don’t need this variable anymore, we can remove it: dt[, very_active := NULL] Sometimes, we would like to filter the data. That is, we select rows according to one or several criteria. Often we would lile to exclude thew very start of the experiment. For example, we can keep data after one hour: dt &lt;- dt[ t &gt; hours(1)] Note that that using dt &lt;- mean we make a new table that overwrite the old one (since it has the same name). Metadata In order to access the metadata, we can add meta = TRUE inside the []: dt[meta = TRUE] ## id sex condition ## 1: toy_experiment|1 male A ## 2: toy_experiment|10 female B ## 3: toy_experiment|2 male B ## 4: toy_experiment|3 male A ## 5: toy_experiment|4 male B ## 6: toy_experiment|5 male A ## 7: toy_experiment|6 female B ## 8: toy_experiment|7 female A ## 9: toy_experiment|8 female B ## 10: toy_experiment|9 female A This way, we can also create new metavariables. For instance, say you want to collapse sex and condition which both have two levels into one treatment, with four levels: dt[, treatment := paste(sex, condition, sep=&#39;|&#39;), meta=T] # just to show the result: dt[meta = TRUE] ## id sex condition treatment ## 1: toy_experiment|1 male A male|A ## 2: toy_experiment|10 female B female|B ## 3: toy_experiment|2 male B male|B ## 4: toy_experiment|3 male A male|A ## 5: toy_experiment|4 male B male|B ## 6: toy_experiment|5 male A male|A ## 7: toy_experiment|6 female B female|B ## 8: toy_experiment|7 female A female|A ## 9: toy_experiment|8 female B female|B ## 10: toy_experiment|9 female A female|A Data &amp; Metadata The strength of behavr tables is their ability to seamlessly use metavariables as though they were variables. For the sake of the example, lets say you would like to alter the variable t (time) so that we add ten seconds, only to individuals that have condition 'A'. dt[, t := ifelse(xmv(condition) == &#39;A&#39;, t + 10, t)] The key here is the use of xmv (eXpand MetaVariable), which maps condition back in the data. We can also use this mechanism to remove individual according to the value of a metavariable. For instance, lets get rid of the males! dt &lt;- dt[xmv(sex) == &#39;female&#39;] summary(dt) ## behavr table with: ## 5 individuals ## 3 metavariables ## 2 variables ## 6.9e+03 measurements ## 1 key (id) When individuals are removed, metadata is automatically updated. In effect, we removed males from both data and metadata. Summerise data Thanks to data table by operations, it is simple and efficient to compute statistics per individual. For instance, we may want to compute the average activity for each animal: stat_dt &lt;- dt[, .(mean_acti = mean(activity)), by=&#39;id&#39;] stat_dt ## ## ==== METADATA ==== ## ## id sex condition treatment ## &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; ## 1: toy_experiment|10 female B female|B ## 2: toy_experiment|6 female B female|B ## 3: toy_experiment|7 female A female|A ## 4: toy_experiment|8 female B female|B ## 5: toy_experiment|9 female A female|A ## ## ====== DATA ====== ## ## id mean_acti ## &lt;char&gt; &lt;num&gt; ## 1: toy_experiment|10 0.4420290 ## 2: toy_experiment|6 0.1615942 ## 3: toy_experiment|7 0.4434783 ## 4: toy_experiment|8 0.1731884 ## 5: toy_experiment|9 0.2550725 You can actually compute many variables in one go this way: stat_dt &lt;- dt[, .(mean_acti = mean(activity), max_acti = max(activity) ), by=&#39;id&#39;] stat_dt ## ## ==== METADATA ==== ## ## id sex condition treatment ## &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; ## 1: toy_experiment|10 female B female|B ## 2: toy_experiment|6 female B female|B ## 3: toy_experiment|7 female A female|A ## 4: toy_experiment|8 female B female|B ## 5: toy_experiment|9 female A female|A ## ## ====== DATA ====== ## ## id mean_acti max_acti ## &lt;char&gt; &lt;num&gt; &lt;int&gt; ## 1: toy_experiment|10 0.4420290 3 ## 2: toy_experiment|6 0.1615942 2 ## 3: toy_experiment|7 0.4434783 3 ## 4: toy_experiment|8 0.1731884 2 ## 5: toy_experiment|9 0.2550725 2 Now, in order to perform statistics, we would lke to merge our summaries to the metadata. That is we want to rejoin them: final_dt &lt;- rejoin(stat_dt) final_dt ## id sex condition treatment mean_acti max_acti ## 1: toy_experiment|10 female B female|B 0.4420290 3 ## 2: toy_experiment|6 female B female|B 0.1615942 2 ## 3: toy_experiment|7 female A female|A 0.4434783 3 ## 4: toy_experiment|8 female B female|B 0.1731884 2 ## 5: toy_experiment|9 female A female|A 0.2550725 2 This table is exactly what you need for statistcis and vidualisation in R! Stitching TODO "],
["damr.html", "DAM2 data, in practice Aims Prerequisites Background Getting the data Experiment design to standard metadata Loading Note on ZT0 Quality control Apply functions when loading Next steps", " DAM2 data, in practice A matter of metadata A DAM experiment. Two replicates, 10 days apart; three genotypes; two sexes, males and females Aims In this practical chapter, we will use a real experiment to learn how to: Translate your experiment design into a metadata file Use this metadata file to load some data Set the circadian reference (ZT0) Assess graphically the quality of the data Use good practices to exclude individuals from our experiments Prerequisites You are familiar with the TriKineticks DAM2 system Ensure you have read about the rethomics workflow and metadata Ensure you have installed behavr, damr and ggetho packages: library(devtools) install_github(&quot;rethomics/behavr&quot;) install_github(&quot;rethomics/damr&quot;) install_github(&quot;rethomics/ggetho&quot;) Background Drosophila Activity Monitors (DAMs) are a wildely used tool to monitor activity of fruit flies over several days. I am assuming that, if you are reading this tutorial, you are already familiar with the system, but I will make a couple of points clear before we start something more hands-on: This tutorial is about single beam DAM2 We work with the raw data (the data from each monitor is in one single file, and all the monitor files are in the same folder) Getting the data For this tutorial, you need to download some DAM2 data that we have made available. This is just a zip archive containng four files. Download and extract the files from the zip into a folder of your choice. Store the path in a variable. For instance, adapt something like: DATA_DIR &lt;- &quot;C://Where/My/Zip/Has/been/extracted Check that all the files live there: list.files(DATA_DIR) ## [1] &quot;damr_tutorial.zip&quot; &quot;metadata.csv&quot; &quot;Monitor11.txt&quot; ## [4] &quot;Monitor14.txt&quot; &quot;Monitor64.txt&quot; For this exercise, we will work with the data and metadata in the same place. In practice, I recommand to: Have all raw data from your acquisition platform in the same place (possibly shared with other or a network drive) Have one folder per “experiment”. That is a folder that contains one metadata file, your R scripts, your figures regarding a set of consistent experiment. For now, we can just set our working directory to DATA_DIR: setwd(DATA_DIR) Experiment design to standard metadata Our toy experiment A DAM experiment. Two replicates, 10 days apart; three genotypes; two sexes, males and females In this example data, we were interested in comparing the behaviour of populations of fruit flies, according to their sex and genotype. We designed the experiment as shown is the figure above. In summary, we have: three genotypes (A, B and C) two sexes (male and female) two replicates (2017-07-01 -&gt; 2017-07-04 and 2017-07-11 -&gt; 2017-07-14) Altogether, 192 individuals Metadata It is crucial that you have read metadata chapter to understand this part. Our goal is to encode our whole experiment in a single file in which: each row is an individual each column is a metavariable Luckily for you, I have already put this file together for you as metadata.csv! Lets have a look at it (you can use R, excel or whatever you want). library(damr) metadata &lt;- fread(&quot;metadata.csv&quot;) metadata ## file start_datetime stop_datetime region_id sex ## 1: Monitor11.txt 2017-07-01 08:00:00 2017-07-04 1 M ## 2: Monitor11.txt 2017-07-01 08:00:00 2017-07-04 2 M ## 3: Monitor11.txt 2017-07-01 08:00:00 2017-07-04 3 M ## 4: Monitor11.txt 2017-07-01 08:00:00 2017-07-04 4 M ## 5: Monitor11.txt 2017-07-01 08:00:00 2017-07-04 5 M ## --- ## 188: Monitor64.txt 2017-07-11 08:00:00 2017-07-14 28 F ## 189: Monitor64.txt 2017-07-11 08:00:00 2017-07-14 29 F ## 190: Monitor64.txt 2017-07-11 08:00:00 2017-07-14 30 F ## 191: Monitor64.txt 2017-07-11 08:00:00 2017-07-14 31 F ## 192: Monitor64.txt 2017-07-11 08:00:00 2017-07-14 32 F ## genotype replicate ## 1: A 1 ## 2: A 1 ## 3: A 1 ## 4: A 1 ## 5: A 1 ## --- ## 188: C 2 ## 189: C 2 ## 190: C 2 ## 191: C 2 ## 192: C 2 Each of the 192 animals (rows) is defined by a set of mandatory columns (metavariables): file – the data file (monitor) that it has been recorded in start_datetime – the date and time (YYYY-MM-DD HH-MM-SS) of the start of the experiment stop_datetime – the last time point of the experiment (time is optional) region_id – the channel ([1, 32]) For our experiment, we also defined custom columns: sex – M and F for male and female, respectively genotype – A, B or C (I just made up the names for the sake of simplicity) replicate – so we can analyse how replicates differ from one another Note that this format is very flexible and explicit. For instance, if we decided to do a third replicate, we would just need to add new rows. We could also add any condition we want as a new column (e.g. treatment, temperature, matting status and so on) Linking Linking is the one necessary step before loading the data. It allocates a unique identifier to each animal. It is very simple to link metadata: metadata &lt;- link_dam2_metadata(metadata, result_dir = DATA_DIR) metadata As result_dir, we just use the directory where the data lives, which you decided when you extracted your data (DATA_DIR). Importantly, you do not need to cut the relevant parts of your DAM files (this is an error-prone step that should be avoided). In other words, no need to use the DAMFileScan utility. You can keep all the data in one file per monitor. rethomics will use start and stop datetime to find the appropriate part directly from your metadata. Loading dt &lt;- load_dam2(metadata) summary(dt) ## behavr table with: ## 192 individuals ## 8 metavariables ## 2 variables ## 7.37472e+05 measurements ## 1 key (id) That is it, all our data is loaded in dt. Note on ZT0 In the circadian and sleep field, we need to align our data to a reference time of the day. Typically, when the light (would) turn on (ZT0). In damr, the time part of the start_datetime is used as a circadian reference. For instance, if you specify, in your metadata file 2017-01-01 09:00:00, you imply that ZT0 is at 09:00:00. The time is looked-up in the DAM file, so it will be at on same time zone settings as the computer that recorded the data. Quality control Detecting anomalies Immediatly after loading your data, you want to have a visualise data to check for anomalies. We can use ggetho for that: library(ggetho) ## Loading required package: ggplot2 # I only show firt replicate ggetho(dt[xmv(replicate) == 1 ], aes(z=activity)) + stat_tile_etho() + stat_ld_annotations() Here, instead of ploting everything, I show how you can subset data according to metadata in order to display only replicate one (dt[xmv(replicate) == 1]). In practice, you could also plot everything. You can do a lot more with ggetho (see the visualisation chapter) What does this tile plot tell us? Each row is an animal (and is labelled with its corresponding id). Each column is a 30min window. The colour intensity indicates the activity. There are two things that we can imediatly notice: For most animals, the activity is rythmic and synchronised with the light phase transisitions. Some animals are dead or missing. For instance take a look at channel 26 in Monitor64.txt. In other chapters, we will learn how to group individuals, visualise and compute statistics. How to exclude animals? The best way to exclude animals a priori (e.g. because they died) is to record them as dead in the metadata. For instance, you can add a column status in your metadata file and put a default value such as &quot;OK&quot;. If an animal is to be removed, you can replace &quot;OK&quot; by a reason (e.g. &quot;dead&quot;, &quot;escaped&quot;, …). Then, you can load your data without those animals load_dam2_data(metadata[status == &quot;OK&quot;], ...). This practice has the advantage of making it very transparent, why some individuals where excluded. Also, it can also easily be reversed. Apply functions when loading Finaly, we may want to apply function on the data as it it loaded, in order to preprocess it. As an example, we can perform a sleep (bouts of immobility of 5 min or more), from our sleepr package (which you will have installed, or course). library(sleepr) # todo #dt &lt;- load_dam2(metadata, FUN = sleepr::sleep_dam_annotation) dt ## ## ==== METADATA ==== ## ## id file_info region_id ## &lt;fctr&gt; &lt;list&gt; &lt;int&gt; ## 1: 2017-07-01 08:00:00|Monitor11.txt|01 &lt;list&gt; 1 ## 2: 2017-07-01 08:00:00|Monitor11.txt|02 &lt;list&gt; 2 ## 3: 2017-07-01 08:00:00|Monitor11.txt|03 &lt;list&gt; 3 ## 4: 2017-07-01 08:00:00|Monitor11.txt|04 &lt;list&gt; 4 ## --- ## 188: 2017-07-11 08:00:00|Monitor64.txt|28 &lt;list&gt; 28 ## 189: 2017-07-11 08:00:00|Monitor64.txt|29 &lt;list&gt; 29 ## 190: 2017-07-11 08:00:00|Monitor64.txt|30 &lt;list&gt; 30 ## 191: 2017-07-11 08:00:00|Monitor64.txt|31 &lt;list&gt; 31 ## 192: 2017-07-11 08:00:00|Monitor64.txt|32 &lt;list&gt; 32 ## experiment_id start_datetime stop_datetime ## &lt;char&gt; &lt;POSc&gt; &lt;char&gt; ## 1: 2017-07-01 08:00:00|Monitor11.txt 2017-07-01 08:00:00 2017-07-04 ## 2: 2017-07-01 08:00:00|Monitor11.txt 2017-07-01 08:00:00 2017-07-04 ## 3: 2017-07-01 08:00:00|Monitor11.txt 2017-07-01 08:00:00 2017-07-04 ## 4: 2017-07-01 08:00:00|Monitor11.txt 2017-07-01 08:00:00 2017-07-04 ## --- ## 188: 2017-07-11 08:00:00|Monitor64.txt 2017-07-11 08:00:00 2017-07-14 ## 189: 2017-07-11 08:00:00|Monitor64.txt 2017-07-11 08:00:00 2017-07-14 ## 190: 2017-07-11 08:00:00|Monitor64.txt 2017-07-11 08:00:00 2017-07-14 ## 191: 2017-07-11 08:00:00|Monitor64.txt 2017-07-11 08:00:00 2017-07-14 ## 192: 2017-07-11 08:00:00|Monitor64.txt 2017-07-11 08:00:00 2017-07-14 ## sex genotype replicate ## &lt;char&gt; &lt;char&gt; &lt;int&gt; ## 1: M A 1 ## 2: M A 1 ## 3: M A 1 ## 4: M A 1 ## --- ## 188: F C 2 ## 189: F C 2 ## 190: F C 2 ## 191: F C 2 ## 192: F C 2 ## ## ====== DATA ====== ## ## id t activity ## &lt;fctr&gt; &lt;num&gt; &lt;int&gt; ## 1: 2017-07-01 08:00:00|Monitor11.txt|01 0 0 ## 2: 2017-07-01 08:00:00|Monitor11.txt|01 60 0 ## 3: 2017-07-01 08:00:00|Monitor11.txt|01 120 0 ## 4: 2017-07-01 08:00:00|Monitor11.txt|01 180 0 ## --- ## 737468: 2017-07-11 08:00:00|Monitor64.txt|32 230160 0 ## 737469: 2017-07-11 08:00:00|Monitor64.txt|32 230220 0 ## 737470: 2017-07-11 08:00:00|Monitor64.txt|32 230280 0 ## 737471: 2017-07-11 08:00:00|Monitor64.txt|32 230340 0 ## 737472: 2017-07-11 08:00:00|Monitor64.txt|32 230400 0 As you can see, we now have additional columns in the data. Next steps Visualise data with ggetho Sleep analysis with sleepr Circadian analysis with zeitgebr "],
["etho-sleep.html", "Sleep analysis with ethoscope", " Sleep analysis with ethoscope "],
["ggetho.html", "Visualisation with ggetho Aims Prerequisites Lessons from ggplot Some behavioural data The ggetho() function Tile plots Population plots Wrapping data LD annotations Coordinate and scales Periodograms Miscelaneous Next steps", " Visualisation with ggetho Make the most of ggetho TODO, a demo of some plots Aims In this practical chapter, we will generate toy data to learn how to: Express a question as a relationship beween variables Use tile plots to show individual data Make population plots Wrap data around circadian time Annotate plot with light and dark phases Use ggplot tools (facets, scales) to enhance plots Plot average and individual periodograms Prerequisites Some familiarity with ggplot Ensure you have installed behavrand ggetho packages: library(devtools) install_github(&quot;rethmics/behavr&quot;) install_github(&quot;rethmics/ggetho&quot;) Lessons from ggplot In the previous tutorials, we have used ggetho to visualise out behavioural data. This section will explain further how this package can be used to produce flexible plots and how it integrates with ggplot2. ggplot2 is one of the most popular visualisation tool and an unavoidable R package. It implements the powerful concepts of the “Grammar of graphics”. The package ggetho, which we discuss here, extends ggplot for the specific case of behavioural analysis. At this stage, you really want to have some familiarity with ggplot2 so you understand its logic. You will find a fair numbers of videos and books online. Some behavioural data In this section, we will simulate toy behavioural data. For that, we start by making some arbitrary metadata. Here, we have 40 animals, condition “A” vs “B”, and sex, male (“M”) or female (“F”). library(ggetho) metadata &lt;- data.table(id=sprintf(&quot;toy_experiment|%02d&quot; , 1:40), region_id=1:40, condition=c(&quot;A&quot;,&quot;B&quot;), sex=c(&quot;M&quot;,&quot;M&quot;, &quot;F&quot;, &quot;F&quot;)) head(metadata) ## id region_id condition sex ## 1: toy_experiment|01 1 A M ## 2: toy_experiment|02 2 B M ## 3: toy_experiment|03 3 A F ## 4: toy_experiment|04 4 B F ## 5: toy_experiment|05 5 A M ## 6: toy_experiment|06 6 B M dt &lt;- toy_activity_data(metadata, seed=107) Now, we have a behavr object, dt: summary(dt) ## behavr table with: ## 40 individuals ## 3 metavariables ## 3 variables ## 1.72804e+06 measurements ## 1 key (id) This data is stored in a behavr table. It has a column moving that that tells us whether an the animal id is moving at a time t. The ggetho() function ggetho() is the core function. It expresses the relationship between variables. In this respect, it works very much like ggplot(), but it also pre-processes the data. For example if we would like: The proportion of time spent moving, on the y axis Versus time, on the x axis We could write: pl &lt;- ggetho(dt, aes(x=t, y=moving)) pl This generates an empty plot this is normal because we have, so far, no layer. We will see some layers very soon! The role of ggetho is to express a relationship between variables and to compute a summary, over a certain time window, of a variable of interest for each individual. Importantly, you decide which variable you want to plot. For instance, you could be interested in things like the number (sum) of beam crosses or the average position. Tile plots Per individual One of the most interesting layer is stat_tile_etho. It shows the variable of interest in the (colour) z axis. The y axis is discrete (generally the id), taht is one row per individual. The x axis is time (by default, summerised, by ggetho, over 30 minutes). So, if we want to show the proportion of time spent moving over time for each individual (id): pl &lt;- ggetho(dt, aes(x=t, y=id, z=moving)) + stat_tile_etho() pl By defaut, each pixel is the mean (summary_FUN = mean, in ggetho), over 30 min (summary_time_window = mins(30), in ggetho()). Also, note that the default is x=t and y=id, so we could just obtain exactly the same with ggetho(dt, aes(z=moving)) + stat_tile_etho(). Sorted individual Sometimes, we want to sort individuals based on a metavariable (discrete or continuous). For instance let us compute the overall average fraction of time spent moving, add it to the metadata, to then sort individuals from low to high movers: First, we add a new metavariable (mean_moving): # the average time spent moving per 1000 (rounded) mean_mov_dt &lt;- dt[, .(mean_moving = round(mean(moving) * 1000)), by=id] # join curent meta and the summary table new_meta &lt;- dt[mean_mov_dt, meta=T] # set new metadata setmeta(dt, new_meta) head(dt[meta=T]) ## id region_id condition sex mean_moving ## 1: toy_experiment|01 1 A M 138 ## 2: toy_experiment|02 2 B M 195 ## 3: toy_experiment|03 3 A F 90 ## 4: toy_experiment|04 4 B F 118 ## 5: toy_experiment|05 5 A M 123 ## 6: toy_experiment|06 6 B M 203 Now, we can express a new relationship where we show the interaction between our custom variable and id, on the y axis: pl &lt;- ggetho(dt, aes(x=t, y=interaction(id, mean_moving, sep = &quot; : &quot;), z=moving)) + stat_tile_etho() pl Since we use &quot; : &quot; as a separator, we have, on the y axis, names as &lt;id&gt; : &lt;mean_sleep&gt;. You can extend this concept to sort also by males vs females: pl &lt;- ggetho(dt, aes(x=t, y=interaction(id, mean_moving, sex, sep = &quot; : &quot;), z=moving)) + stat_tile_etho() pl Group averages Sometimes, we also want to aggregate individuals per group. For instance, males average vs females average: pl &lt;- ggetho(dt, aes(x=t, y=sex, z=moving)) + stat_tile_etho() pl In this context, every row is not an individual any more, but a group. The method argument of stat_tile_etho() allows you to use other aggregates (median, max, min, …). Population plots One population The problem with representing a variable on a colour axis is that it is not perceptually comparable, and we cannot make error bars. When the number of groups is not too high, it makes sense to show the variable of interest on the y axis, and then draw lines between consecutive points. For this, we can use the stat_pop_etho() function: pl &lt;- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() pl By defaut, the local average and error bars are computed from the mean an standard errors (method = mean_se). You can compute other types of error bars e.g. bootstrap (method = mean_cl_boot). Several populations Often, we want to compare population with respect to a variable. There are different way to split populations. We can, for instance, use a different colour line for different groups: pl &lt;- ggetho(dt, aes(x=t, y=moving, colour=sex)) + stat_pop_etho() pl Another way, is to use ggplot’s faceting system: pl &lt;- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() + facet_grid(sex ~ .) pl Of course, you can combine both when you have more than one relevant metavariable: pl &lt;- ggetho(dt, aes(x=t, y=moving, colour = sex)) + stat_pop_etho() + facet_grid( condition ~ .) pl Wrapping data When behaviours are periodic, we sometimes want to average our variable at the same time over consecutive days. In ggetho, we call that time wrapping. It can be done simply with the time_wrap argument. It will work the same for population or tile plots: pl &lt;- ggetho(dt, aes(x=t, y=moving), time_wrap = hours(24)) + stat_pop_etho() pl Note that you do not have to wrap over specifically 24h, you could work different periods. LD annotations Basics In circadian experiments, we often like to add annotations (black and white boxes) to show Dark and Light phases. We have another layer for that: pl &lt;- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() + stat_ld_annotations() pl Changing LD colours Sometimes you want different colours to explains, for instance, that days are “subjective”(grey). pl &lt;- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() + stat_ld_annotations(ld_colours = c(&quot;grey&quot;, &quot;black&quot;)) pl LD in the background To put the annotation in the background, we can invert the order of the layers, set the heigh of the annotation to 1 (100%) and add some transparency (alpha = 0.3). We also remove the outline of the boxes: pl &lt;- ggetho(dt, aes(x=t, y=moving)) + stat_ld_annotations(height=1, alpha=0.3, outline = NA) + stat_pop_etho() pl Phase and period Sometimes you want to show annotations with different phases and periods. For instance, here, we shift the LD annotations 1h forward: pl &lt;- ggetho(dt, aes(x=t, y=moving)) + stat_ld_annotations(phase = hours(1)) + stat_pop_etho() pl One can also plot over a period different from 24h, say 20h days: pl &lt;- ggetho(dt, aes(x=t, y=moving)) + stat_ld_annotations(period = hours(20)) + stat_pop_etho() pl Regime change When, you want to indicate a change in regime, say from LD to DD. A simple way is to use multiple layers with explicit start and end points: pl &lt;- ggetho(dt, aes(x=t, y=moving)) + # the default annotation layer stat_ld_annotations() + # on top of it, a second layer that # starts at day 2 thoughout day 5, # and where L colour is grey stat_ld_annotations(x_limits = days(c(2,5)), ld_colours = c(&quot;grey&quot;, &quot;black&quot; )) + stat_pop_etho() pl Coordinate and scales Plot limits As ggetho creates regular ggplot objects, which we can extend. For instance, we can change the scales. For instance, put the y scale as a percentage between 0 and 100: pl &lt;- ggetho(dt, aes(x=t, y=moving)) + stat_pop_etho() + stat_ld_annotations() pl &lt;- pl + scale_y_continuous(limits = c(0,1), labels = scales::percent) pl We can also use the same principle to zoom in a finished plot. E.g. between day one and day two: pl + coord_cartesian(xlim=c(days(1), days(2))) Time scale units By default, ggetho decides the unit of the time axis according to the range of the data. Sometime you want to override this behaviour to force time to be in a specific unit (here hours). Using the plot above, we can add a scale: pl + ggetho::scale_x_hours() ## Scale for &#39;x&#39; is already present. Adding another scale for &#39;x&#39;, which ## will replace the existing scale. R actually warns you since you are replacing the scale. Which is fine (as it is precisely what we wanted)! Coordinate systems Sometimes, it makes sense to use polar coordinates to show data around the clock: pl &lt;- ggetho(dt, aes(x=t, y=moving, colour=sex), time_wrap = days(1)) + stat_ld_annotations(height=.5, alpha=.2, x_limits = c(0, days(1)), outline = NA) + stat_pop_etho(geom = &quot;polygon&quot;, fill=NA) pl + coord_polar() Periodograms TODO library(zeitgebr) dt[, t := ifelse(xmv(condition) == &quot;A&quot;, t, t * 1.01)] per_dt &lt;- periodogram(moving, dt, FUN = chi_sq_periodogram) per_dt ## ## ==== METADATA ==== ## ## id region_id condition sex mean_moving ## &lt;char&gt; &lt;int&gt; &lt;char&gt; &lt;char&gt; &lt;num&gt; ## 1: toy_experiment|01 1 A M 138 ## 2: toy_experiment|02 2 B M 195 ## 3: toy_experiment|03 3 A F 90 ## 4: toy_experiment|04 4 B F 118 ## 5: toy_experiment|05 5 A M 123 ## 6: toy_experiment|06 6 B M 203 ## 7: toy_experiment|07 7 A F 88 ## 8: toy_experiment|08 8 B F 144 ## 9: toy_experiment|09 9 A M 192 ## 10: toy_experiment|10 10 B M 126 ## 11: toy_experiment|11 11 A F 86 ## 12: toy_experiment|12 12 B F 208 ## 13: toy_experiment|13 13 A M 187 ## 14: toy_experiment|14 14 B M 205 ## 15: toy_experiment|15 15 A F 155 ## 16: toy_experiment|16 16 B F 116 ## 17: toy_experiment|17 17 A M 101 ## 18: toy_experiment|18 18 B M 98 ## 19: toy_experiment|19 19 A F 46 ## 20: toy_experiment|20 20 B F 70 ## 21: toy_experiment|21 21 A M 209 ## 22: toy_experiment|22 22 B M 110 ## 23: toy_experiment|23 23 A F 160 ## 24: toy_experiment|24 24 B F 79 ## 25: toy_experiment|25 25 A M 70 ## 26: toy_experiment|26 26 B M 208 ## 27: toy_experiment|27 27 A F 216 ## 28: toy_experiment|28 28 B F 77 ## 29: toy_experiment|29 29 A M 217 ## 30: toy_experiment|30 30 B M 227 ## 31: toy_experiment|31 31 A F 39 ## 32: toy_experiment|32 32 B F 101 ## 33: toy_experiment|33 33 A M 182 ## 34: toy_experiment|34 34 B M 198 ## 35: toy_experiment|35 35 A F 209 ## 36: toy_experiment|36 36 B F 105 ## 37: toy_experiment|37 37 A M 228 ## 38: toy_experiment|38 38 B M 78 ## 39: toy_experiment|39 39 A F 59 ## 40: toy_experiment|40 40 B F 84 ## id region_id condition sex mean_moving ## ## ====== DATA ====== ## ## id period power signif_threshold ## &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; ## 1: toy_experiment|01 57600 841.5578 1116.799 ## 2: toy_experiment|01 57960 778.3099 1123.266 ## 3: toy_experiment|01 58320 698.7854 1129.731 ## 4: toy_experiment|01 58680 668.9010 1136.195 ## --- ## 6436: toy_experiment|40 113760 1159.5760 2113.450 ## 6437: toy_experiment|40 114120 1139.5876 2119.782 ## 6438: toy_experiment|40 114480 1212.7457 2126.114 ## 6439: toy_experiment|40 114840 1157.6422 2132.445 ## 6440: toy_experiment|40 115200 1159.2151 2138.776 ggplot(rejoin(per_dt), aes(period, power, colour=condition)) + geom_line(mapping = aes(group = id), alpha=.1) + scale_x_hours() + stat_summary(geom=&quot;smooth&quot;, fun.data = mean_se) Miscelaneous TODO, list ggplot possibilities: Use other geom annotate change title Axis names Next steps TODO "]
]
